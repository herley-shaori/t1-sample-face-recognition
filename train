#!/usr/bin/env python

# A sample training component that trains a simple scikit-learn decision tree model.
# This implementation works in File mode and makes no assumptions about the input file names.
# Input is specified as CSV with a data point in each row and the labels in the first column.

from __future__ import print_function

import pickle
import sys
import traceback
import boto3
import os
import numpy as np
import cv2
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score

# These are the paths to where SageMaker mounts interesting things in your container.

prefix = '/opt/ml/'

input_path = prefix + 'input/data'
output_path = os.path.join(prefix, 'output')
model_path = os.path.join(prefix, 'model')
param_path = os.path.join(prefix, 'input/config/hyperparameters.json')

# This algorithm has a single channel of input data called 'training'. Since we run in
# File mode, the input files are copied to the directory specified here.
channel_name='training'
training_path = os.path.join(input_path, channel_name)

# The function to execute the training.
def train():
    try:
        print('Starting the training.')
        cropped_images_folder = 'cropped_images'
        # Load cropped images and labels (assuming labels are in filenames)
        X_train = []
        y_train = []
        for filename in os.listdir(cropped_images_folder):
            img = cv2.imread(os.path.join(cropped_images_folder, filename))
            X_train.append(img.flatten())  # Flatten for classification
            y_train.append(filename.split("_")[0])  # Assuming label is in filename

        # Ensure consistent array shape
        max_shape = (max([img.shape[0] for img in X_train]),)
        X_train_padded = [np.pad(img, ((0, max_shape[0] - img.shape[0])), mode='constant') for img in X_train]

        # Split into training and testing sets
        X_train, X_test, y_train, y_test = train_test_split(X_train_padded, y_train, test_size=0.2, random_state=42)

        # Create DataFrames from NumPy arrays:
        X_train_df = pd.DataFrame(X_train)
        X_test_df = pd.DataFrame(X_test)
        y_train_df = pd.DataFrame(y_train)
        y_test_df = pd.DataFrame(y_test)

        # Automate feature names:
        num_features = 56307
        X_train_df.columns = [f'feature_{i}' for i in range(num_features)]
        X_test_df.columns = X_train_df.columns  # Use the same column names for consistency

        # Set target variable name:
        y_train_df.columns = ['target']
        y_test_df.columns = y_train_df.columns

        # Add y_train as the first column of X_train_df:
        X_train_df = pd.concat([y_train_df, X_train_df], axis=1)

        X_train_df.to_csv('train.csv', index=False)

        # Train SVM and Naive Bayes models
        svm_model = SVC().fit(X_train, y_train)
        nb_model = GaussianNB().fit(X_train, y_train)

        # Evaluate models
        currentF1Score = None
        for model in [svm_model, nb_model]:
            y_pred = model.predict(X_test)
            cm = confusion_matrix(y_test, y_pred)
            precision = precision_score(y_test, y_pred, average="weighted")
            recall = recall_score(y_test, y_pred, average="weighted")
            f1 = f1_score(y_test, y_pred, average="weighted")
            print("Model:", model.__class__.__name__)
            print("Confusion Matrix:\n", cm)
            print("Precision:", precision)
            print("Recall:", recall)
            print("F1-score:", f1)
            # Save the best model.
            if (currentF1Score is None or f1 > currentF1Score):
                currentF1Score = f1
                with open(os.path.join(model_path, 'model.pkl'), 'wb') as out:
                    pickle.dump(model, out)
                with open(os.path.join('model.pkl'), 'wb') as out:
                    pickle.dump(model, out)
                s3 = boto3.client('s3')
                s3.upload_file('model.pkl', 'temp-data-for-rekognition', 'byom-model/model.pkl')
    except Exception as e:
        # Write out an error file. This will be returned as the failureReason in the
        # DescribeTrainingJob result.
        trc = traceback.format_exc()
        with open(os.path.join(output_path, 'failure'), 'w') as s:
            s.write('Exception during training: ' + str(e) + '\n' + trc)
        # Printing this causes the exception to be in the training job logs, as well.
        print('Exception during training: ' + str(e) + '\n' + trc, file=sys.stderr)
        # A non-zero exit code causes the training job to be marked as Failed.
        sys.exit(255)

if __name__ == '__main__':
    train()
    # A zero exit code causes the job to be marked a Succeeded.
    sys.exit(0)